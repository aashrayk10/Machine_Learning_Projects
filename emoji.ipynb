{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emoji_dictionary={\n",
    "    \"0\":\":beating_heart:\",\n",
    "    \"1\":\":baseball:\",\n",
    "    \"2\":\":beaming_face_with_smiling_eyes:\",\n",
    "    \"3\":\":downcast_face_with_sweat:\",\n",
    "    \"4\":\":fork_and_knife:\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train_emoji.csv\")\n",
    "test=pd.read_csv(\"test_emoji.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>never talk to me again</th>\n",
       "      <th>3</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love you mum</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop saying bullshit</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>congratulations on your acceptance</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The assignment is too long</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I want to go play</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>she did not answer my text</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               never talk to me again  3  Unnamed: 2 Unnamed: 3\n",
       "0     I am proud of your achievements  2         NaN        NaN\n",
       "1      It is the worst day in my life  3         NaN        NaN\n",
       "2                    Miss you so much  0         NaN        [0]\n",
       "3                        food is life  4         NaN        NaN\n",
       "4                      I love you mum  0         NaN        NaN\n",
       "5                Stop saying bullshit  3         NaN        NaN\n",
       "6  congratulations on your acceptance  2         NaN        NaN\n",
       "7         The assignment is too long   3         NaN        NaN\n",
       "8                   I want to go play  1         NaN        [3]\n",
       "9         she did not answer my text   3         NaN        NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train[:,0]\n",
    "y_train=train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131,) (131,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55,) (55,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test=test.values\n",
    "x_test=test[:,0]\n",
    "y_test=test[:,1]\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am proud of your achievements üòÅ\n",
      "It is the worst day in my life üòì\n",
      "Miss you so much üíì\n",
      "food is life üç¥\n",
      "I love you mum üíì\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(x_train[i],emoji.emojize(emoji_dictionary.get(str(y_train[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 5) (55, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"glove.6B.50d.txt\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings={}\n",
    "for line in f:\n",
    "    data=line.split()\n",
    "    word=data[0]\n",
    "    values=np.array(data[1:],dtype=\"float32\")\n",
    "    embeddings[word]=values\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38497   0.80092   0.064106 -0.28355  -0.026759 -0.34532  -0.64253\n",
      " -0.11729  -0.33257   0.55243  -0.087813  0.9035    0.47102   0.56657\n",
      "  0.6985   -0.35229  -0.86542   0.90573   0.03576  -0.071705 -0.12327\n",
      "  0.54923   0.47005   0.35572   1.2611   -0.67581  -0.94983   0.68666\n",
      "  0.3871   -1.3492    0.63512   0.46416  -0.48814   0.83827  -0.9246\n",
      " -0.33722   0.53741  -1.0616   -0.081403 -0.67111   0.30923  -0.3923\n",
      " -0.55002  -0.68827   0.58049  -0.11626   0.013139 -0.57654   0.048833\n",
      "  0.67204 ]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings[\"hello\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(embeddings[\"shape\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embedding_output(X,maxlen=10):\n",
    "    embedding_output=np.zeros((X.shape[0],maxlen,50))\n",
    "    for i in range(X.shape[0]):\n",
    "        X[i]=X[i].split()\n",
    "        for j in range(len(X[i])):\n",
    "            try:\n",
    "                embedding_output[i][j]=embeddings[X[i][j].lower()]\n",
    "            except:\n",
    "                embedding_output[i][j]=np.zeros((50,))\n",
    "    return embedding_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedded_x_train=embedding_output(x_train)\n",
    "embedded_x_test=embedding_output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'proud', 'of', 'your', 'achievements']\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 10, 50) (55, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedded_x_train.shape,embedded_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 141,381\n",
      "Trainable params: 141,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()\n",
    "         \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "Checkpoint=ModelCheckpoint(\"best_model.h5\",monitor='val_acc',save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104 samples, validate on 27 samples\n",
      "Epoch 1/80\n",
      "104/104 [==============================] - 2s 16ms/step - loss: 1.5627 - accuracy: 0.3269 - val_loss: 1.6170 - val_accuracy: 0.2222\n",
      "Epoch 2/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.5238 - accuracy: 0.3269 - val_loss: 1.6439 - val_accuracy: 0.2222\n",
      "Epoch 3/80\n",
      " 64/104 [=================>............] - ETA: 0s - loss: 1.4480 - accuracy: 0.3906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 930us/step - loss: 1.4929 - accuracy: 0.3654 - val_loss: 1.6776 - val_accuracy: 0.2593\n",
      "Epoch 4/80\n",
      "104/104 [==============================] - 0s 825us/step - loss: 1.4486 - accuracy: 0.4423 - val_loss: 1.6778 - val_accuracy: 0.2222\n",
      "Epoch 5/80\n",
      "104/104 [==============================] - 0s 853us/step - loss: 1.4254 - accuracy: 0.4038 - val_loss: 1.6537 - val_accuracy: 0.2222\n",
      "Epoch 6/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.3994 - accuracy: 0.4519 - val_loss: 1.6065 - val_accuracy: 0.2222\n",
      "Epoch 7/80\n",
      "104/104 [==============================] - 0s 1000us/step - loss: 1.3470 - accuracy: 0.4904 - val_loss: 1.5654 - val_accuracy: 0.2222\n",
      "Epoch 8/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.2696 - accuracy: 0.5192 - val_loss: 1.5132 - val_accuracy: 0.2963\n",
      "Epoch 9/80\n",
      "104/104 [==============================] - 0s 795us/step - loss: 1.1738 - accuracy: 0.5962 - val_loss: 1.4563 - val_accuracy: 0.3333\n",
      "Epoch 10/80\n",
      "104/104 [==============================] - 0s 825us/step - loss: 1.1519 - accuracy: 0.5962 - val_loss: 1.3901 - val_accuracy: 0.3333\n",
      "Epoch 11/80\n",
      "104/104 [==============================] - 0s 911us/step - loss: 1.0515 - accuracy: 0.6346 - val_loss: 1.3430 - val_accuracy: 0.3704\n",
      "Epoch 12/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.9802 - accuracy: 0.6538 - val_loss: 1.3066 - val_accuracy: 0.4815\n",
      "Epoch 13/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.9591 - accuracy: 0.7019 - val_loss: 1.2890 - val_accuracy: 0.5556\n",
      "Epoch 14/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.8541 - accuracy: 0.7212 - val_loss: 1.2197 - val_accuracy: 0.5185\n",
      "Epoch 15/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.7647 - accuracy: 0.7885 - val_loss: 1.1754 - val_accuracy: 0.5926\n",
      "Epoch 16/80\n",
      "104/104 [==============================] - 0s 889us/step - loss: 0.6819 - accuracy: 0.7788 - val_loss: 1.1416 - val_accuracy: 0.5926\n",
      "Epoch 17/80\n",
      "104/104 [==============================] - 0s 776us/step - loss: 0.7218 - accuracy: 0.7788 - val_loss: 1.1780 - val_accuracy: 0.5556\n",
      "Epoch 18/80\n",
      "104/104 [==============================] - 0s 923us/step - loss: 0.6294 - accuracy: 0.7981 - val_loss: 1.2937 - val_accuracy: 0.5556\n",
      "Epoch 19/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.6181 - accuracy: 0.7788 - val_loss: 1.0759 - val_accuracy: 0.5926\n",
      "Epoch 20/80\n",
      "104/104 [==============================] - 0s 921us/step - loss: 0.4565 - accuracy: 0.8365 - val_loss: 1.0408 - val_accuracy: 0.5556\n",
      "Epoch 21/80\n",
      "104/104 [==============================] - 0s 767us/step - loss: 0.4714 - accuracy: 0.8654 - val_loss: 0.9720 - val_accuracy: 0.6296\n",
      "Epoch 22/80\n",
      "104/104 [==============================] - 0s 796us/step - loss: 0.4456 - accuracy: 0.8846 - val_loss: 0.9201 - val_accuracy: 0.7407\n",
      "Epoch 23/80\n",
      "104/104 [==============================] - 0s 796us/step - loss: 0.3707 - accuracy: 0.8942 - val_loss: 1.1102 - val_accuracy: 0.5556\n",
      "Epoch 24/80\n",
      "104/104 [==============================] - 0s 786us/step - loss: 0.3932 - accuracy: 0.8750 - val_loss: 0.9376 - val_accuracy: 0.7037\n",
      "Epoch 25/80\n",
      "104/104 [==============================] - 0s 815us/step - loss: 0.3639 - accuracy: 0.8942 - val_loss: 1.1916 - val_accuracy: 0.6296\n",
      "Epoch 26/80\n",
      "104/104 [==============================] - 0s 831us/step - loss: 0.3831 - accuracy: 0.8558 - val_loss: 0.8677 - val_accuracy: 0.6667\n",
      "Epoch 27/80\n",
      "104/104 [==============================] - 0s 796us/step - loss: 0.2760 - accuracy: 0.9135 - val_loss: 0.9690 - val_accuracy: 0.6667\n",
      "Epoch 28/80\n",
      "104/104 [==============================] - 0s 805us/step - loss: 0.2757 - accuracy: 0.9135 - val_loss: 0.8260 - val_accuracy: 0.6296\n",
      "Epoch 29/80\n",
      "104/104 [==============================] - 0s 853us/step - loss: 0.2714 - accuracy: 0.9135 - val_loss: 0.8783 - val_accuracy: 0.6667\n",
      "Epoch 30/80\n",
      "104/104 [==============================] - 0s 988us/step - loss: 0.2128 - accuracy: 0.9423 - val_loss: 0.9989 - val_accuracy: 0.5926\n",
      "Epoch 31/80\n",
      "104/104 [==============================] - 0s 835us/step - loss: 0.2193 - accuracy: 0.9135 - val_loss: 1.2027 - val_accuracy: 0.6296\n",
      "Epoch 32/80\n",
      "104/104 [==============================] - 0s 810us/step - loss: 0.1992 - accuracy: 0.9519 - val_loss: 1.1550 - val_accuracy: 0.5926\n",
      "Epoch 33/80\n",
      "104/104 [==============================] - 0s 837us/step - loss: 0.1919 - accuracy: 0.9327 - val_loss: 1.1365 - val_accuracy: 0.5926\n",
      "Epoch 34/80\n",
      "104/104 [==============================] - 0s 911us/step - loss: 0.1404 - accuracy: 0.9712 - val_loss: 1.1679 - val_accuracy: 0.6296\n",
      "Epoch 35/80\n",
      "104/104 [==============================] - 0s 853us/step - loss: 0.1467 - accuracy: 0.9712 - val_loss: 1.0654 - val_accuracy: 0.6667\n",
      "Epoch 36/80\n",
      "104/104 [==============================] - 0s 807us/step - loss: 0.1291 - accuracy: 0.9712 - val_loss: 1.0639 - val_accuracy: 0.7037\n",
      "Epoch 37/80\n",
      "104/104 [==============================] - 0s 806us/step - loss: 0.1208 - accuracy: 0.9615 - val_loss: 1.1701 - val_accuracy: 0.6667\n",
      "Epoch 38/80\n",
      "104/104 [==============================] - 0s 796us/step - loss: 0.1050 - accuracy: 0.9808 - val_loss: 1.2227 - val_accuracy: 0.5926\n",
      "Epoch 39/80\n",
      "104/104 [==============================] - 0s 767us/step - loss: 0.0858 - accuracy: 0.9808 - val_loss: 1.2885 - val_accuracy: 0.5926\n",
      "Epoch 40/80\n",
      "104/104 [==============================] - 0s 806us/step - loss: 0.1030 - accuracy: 0.9808 - val_loss: 1.2442 - val_accuracy: 0.6667\n",
      "Epoch 41/80\n",
      "104/104 [==============================] - 0s 817us/step - loss: 0.0802 - accuracy: 0.9808 - val_loss: 1.3103 - val_accuracy: 0.6667\n",
      "Epoch 42/80\n",
      "104/104 [==============================] - 0s 795us/step - loss: 0.0809 - accuracy: 0.9615 - val_loss: 1.3004 - val_accuracy: 0.6667\n",
      "Epoch 43/80\n",
      "104/104 [==============================] - 0s 767us/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.2575 - val_accuracy: 0.6667\n",
      "Epoch 44/80\n",
      "104/104 [==============================] - 0s 844us/step - loss: 0.0610 - accuracy: 0.9904 - val_loss: 1.3499 - val_accuracy: 0.6296\n",
      "Epoch 45/80\n",
      "104/104 [==============================] - 0s 785us/step - loss: 0.0738 - accuracy: 0.9904 - val_loss: 1.4850 - val_accuracy: 0.6667\n",
      "Epoch 46/80\n",
      "104/104 [==============================] - 0s 766us/step - loss: 0.0545 - accuracy: 0.9904 - val_loss: 1.4984 - val_accuracy: 0.6667\n",
      "Epoch 47/80\n",
      "104/104 [==============================] - 0s 796us/step - loss: 0.0475 - accuracy: 0.9904 - val_loss: 1.2798 - val_accuracy: 0.6667\n",
      "Epoch 48/80\n",
      "104/104 [==============================] - 0s 786us/step - loss: 0.0443 - accuracy: 0.9904 - val_loss: 1.3250 - val_accuracy: 0.6667\n",
      "Epoch 49/80\n",
      "104/104 [==============================] - 0s 796us/step - loss: 0.0883 - accuracy: 0.9712 - val_loss: 1.1911 - val_accuracy: 0.7037\n",
      "Epoch 50/80\n",
      "104/104 [==============================] - 0s 748us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 1.1505 - val_accuracy: 0.7037\n",
      "Epoch 51/80\n",
      "104/104 [==============================] - 0s 806us/step - loss: 0.1252 - accuracy: 0.9712 - val_loss: 1.1941 - val_accuracy: 0.6296\n",
      "Epoch 52/80\n",
      "104/104 [==============================] - 0s 806us/step - loss: 0.1183 - accuracy: 0.9615 - val_loss: 1.5503 - val_accuracy: 0.6296\n",
      "Epoch 53/80\n",
      "104/104 [==============================] - 0s 815us/step - loss: 0.1400 - accuracy: 0.9615 - val_loss: 0.9666 - val_accuracy: 0.7037\n",
      "Epoch 54/80\n",
      "104/104 [==============================] - 0s 978us/step - loss: 0.0623 - accuracy: 0.9712 - val_loss: 1.1635 - val_accuracy: 0.6667\n",
      "Epoch 55/80\n",
      "104/104 [==============================] - 0s 853us/step - loss: 0.0833 - accuracy: 0.9808 - val_loss: 1.1928 - val_accuracy: 0.6667\n",
      "Epoch 56/80\n",
      "104/104 [==============================] - 0s 796us/step - loss: 0.0438 - accuracy: 0.9904 - val_loss: 1.2959 - val_accuracy: 0.6296\n",
      "Epoch 57/80\n",
      "104/104 [==============================] - 0s 838us/step - loss: 0.0455 - accuracy: 0.9808 - val_loss: 1.5349 - val_accuracy: 0.6296\n",
      "Epoch 58/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 1.6123 - val_accuracy: 0.6667\n",
      "Epoch 59/80\n",
      "104/104 [==============================] - 0s 786us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 1.6169 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/80\n",
      "104/104 [==============================] - 0s 950us/step - loss: 0.0441 - accuracy: 0.9904 - val_loss: 1.7026 - val_accuracy: 0.6296\n",
      "Epoch 61/80\n",
      "104/104 [==============================] - 0s 831us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.8140 - val_accuracy: 0.5926\n",
      "Epoch 62/80\n",
      "104/104 [==============================] - 0s 748us/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 1.7753 - val_accuracy: 0.6296\n",
      "Epoch 63/80\n",
      "104/104 [==============================] - 0s 835us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.9161 - val_accuracy: 0.6667\n",
      "Epoch 64/80\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9712 - val_loss: 1.6111 - val_accuracy: 0.6296\n",
      "Epoch 65/80\n",
      "104/104 [==============================] - 0s 902us/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.2525 - val_accuracy: 0.6296\n",
      "Epoch 66/80\n",
      "104/104 [==============================] - 0s 929us/step - loss: 0.0351 - accuracy: 0.9904 - val_loss: 1.4274 - val_accuracy: 0.6296\n",
      "Epoch 67/80\n",
      "104/104 [==============================] - 0s 997us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.5712 - val_accuracy: 0.6296\n",
      "Epoch 68/80\n",
      "104/104 [==============================] - 0s 960us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.6054 - val_accuracy: 0.6667\n",
      "Epoch 69/80\n",
      "104/104 [==============================] - 0s 904us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.5709 - val_accuracy: 0.6667\n",
      "Epoch 70/80\n",
      "104/104 [==============================] - 0s 916us/step - loss: 0.0271 - accuracy: 0.9904 - val_loss: 1.5935 - val_accuracy: 0.6296\n",
      "Epoch 71/80\n",
      "104/104 [==============================] - 0s 892us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.6296\n",
      "Epoch 72/80\n",
      "104/104 [==============================] - 0s 873us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.8305 - val_accuracy: 0.6296\n",
      "Epoch 73/80\n",
      "104/104 [==============================] - 0s 848us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.7385 - val_accuracy: 0.6296\n",
      "Epoch 74/80\n",
      "104/104 [==============================] - 0s 921us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.7167 - val_accuracy: 0.5926\n",
      "Epoch 75/80\n",
      "104/104 [==============================] - 0s 892us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.7727 - val_accuracy: 0.6296\n",
      "Epoch 76/80\n",
      "104/104 [==============================] - 0s 930us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.8213 - val_accuracy: 0.6667\n",
      "Epoch 77/80\n",
      "104/104 [==============================] - 0s 966us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.7962 - val_accuracy: 0.6667\n",
      "Epoch 78/80\n",
      "104/104 [==============================] - 0s 863us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.6943 - val_accuracy: 0.6667\n",
      "Epoch 79/80\n",
      "104/104 [==============================] - 0s 882us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.5846 - val_accuracy: 0.6667\n",
      "Epoch 80/80\n",
      "104/104 [==============================] - 0s 901us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.5018 - val_accuracy: 0.7037\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(embedded_x_train,y_train,epochs=80,batch_size=64,shuffle=True,validation_split=0.2,callbacks=[Checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 329us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0276828397404065, 0.6363636255264282]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(embedded_x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict_classes(embedded_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he did not answer üòì\n",
      "he got a raise üòÅ\n",
      "she got me a present üòÅ\n",
      "ha ha ha it was so funny üòÅ\n",
      "he is a good friend üòÅ\n",
      "I am upset ‚öæ\n",
      "We had such a lovely dinner tonight üòÅ\n",
      "where is the food üç¥\n",
      "Stop making this joke ha ha ha üòÅ\n",
      "where is the ball ‚öæ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    print(\" \".join(x_test[i]),emoji.emojize(emoji_dictionary[str(predict[i])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
